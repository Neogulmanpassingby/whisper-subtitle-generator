import whisper
import os
import sys
import torch



def transcribe_to_srt(video_path):
    # íŒŒì¼ ê²½ë¡œ ê²€ì‚¬
    if not os.path.exists(video_path):
        print("âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤:", video_path)
        return

    # Whisper ëª¨ë¸ ë¡œë“œ
    model = whisper.load_model("large")  # í•„ìš”ì‹œ small, medium, large ê°€ëŠ¥

    print("ğŸ”Š ìŒì„± ì¸ì‹ ì¤‘...")
    result = model.transcribe(video_path)

    # .srt íŒŒì¼ ê²½ë¡œ ì„¤ì •
    base_name = os.path.splitext(video_path)[0]
    srt_path = base_name + ".srt"

    with open(srt_path, "w", encoding="utf-8") as f:
        for i, segment in enumerate(result["segments"]):
            start = segment["start"]
            end = segment["end"]
            text = segment["text"]

            def format_time(seconds):
                h = int(seconds // 3600)
                m = int((seconds % 3600) // 60)
                s = seconds % 60
                return f"{h:02}:{m:02}:{int(s):02},{int((s % 1)*1000):03}"

            f.write(f"{i+1}\n")
            f.write(f"{format_time(start)} --> {format_time(end)}\n")
            f.write(text.strip() + "\n\n")

    print(f"âœ… SRT ìë§‰ ìƒì„± ì™„ë£Œ: {srt_path}")


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("ì‚¬ìš©ë²•: python generate_srt.py ì˜ìƒíŒŒì¼ê²½ë¡œ")
        sys.exit(1)
    print("GPU ì‚¬ìš© ì—¬ë¶€:", torch.cuda.is_available()) 

    video_path = sys.argv[1]
    transcribe_to_srt(video_path)
